{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, copy, cv2\n",
    "import networkx as nx\n",
    "import sys,glob\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import gudhi as gd\n",
    "from gudhi.representations import vector_methods\n",
    "import ripser\n",
    "import persim\n",
    "from TDA_filtrations import level_set_flooding, save_BD, image_to_pointcloud\n",
    "from custom_functions import *\n",
    "import multiprocessing as mp\n",
    "import skimage.measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### To select a dataset to analyze, uncomment all code under the dataset's name\n",
    "\n",
    "### STARE Expert #1\n",
    "dataset = \"STARE1\"\n",
    "nefi_output_folder = \"../Data/Dataset_1/NEFI_graphs/*/\"\n",
    "image_folder = \"../Data/Dataset_1/Provided_masks/\"\n",
    "write_folder = \"../Results/Dataset_1/\"\n",
    "\n",
    "###STARE Expert #2\n",
    "'''dataset = \"STARE2\"\n",
    "nefi_output_folder = \"../Data/Dataset_1/NEFI_graphs_VK/*/\"\n",
    "image_folder = \"../Data/Dataset_1/Provided_masks_VK/\"\n",
    "write_folder = \"../Results/Dataset_1_VK/\"'''\n",
    "\n",
    "### HRF\n",
    "'''dataset = \"HRF\"\n",
    "nefi_output_folder = \"../Data/HRF_Dataset_1/NEFI_graphs/*/\"\n",
    "image_folder = \"../Data/HRF_Dataset_1/Provided_masks/\"\n",
    "write_folder = \"../Results/HRF_Dataset_1/\"'''\n",
    "\n",
    "### All\n",
    "'''dataset = \"all\"\n",
    "nefi_output_folder = \"../Data/all/NEFI_graphs/*/\"\n",
    "image_folder = \"../Data/all/Provided_masks/\"\n",
    "write_folder = \"../Results/all/\"'''\n",
    "\n",
    "\n",
    "#To help with indexing and loading disease classifications\n",
    "if dataset == \"HRF\":\n",
    "    nums = np.arange(1,46)\n",
    "    #mat = np.load(\"../Data/Diagnoses/image_diagnoses_HRF.npy\",allow_pickle=True).item()\n",
    "elif \"STARE\" in dataset:\n",
    "    nums = np.array([1,2,3,4,5,44,77,81,82,139,162, 163, 235, 236, 239, 240, 255, 291, 319, 324])\n",
    "    #mat = np.load(\"../Data/Diagnoses/image_diagnoses.npy\",allow_pickle=True).item()    \n",
    "elif \"all\" in dataset:    \n",
    "    mat = np.load(\"../Data/Diagnoses/image_diagnoses_all.npy\",allow_pickle=True).item()    \n",
    "    nums = list(mat['image_diagnoses'].keys())\n",
    "    \n",
    "data_name = \"DS1_\"    \n",
    "file_name = \"im\"    \n",
    "nefi_outputs = glob.glob(f\"{nefi_output_folder}*.txt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Radial inward and Radial outward filtrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_filtrations(num):\n",
    "    \n",
    "    if \"all\" in dataset:\n",
    "        num_str = num\n",
    "    else:\n",
    "        num_str = f\"{str(num).zfill(4)}\"\n",
    "        \n",
    "    if dataset == \"HRF\":\n",
    "        max_rad = 3000\n",
    "    else:\n",
    "        max_rad = 700\n",
    "    \n",
    "    #find nefi output file\n",
    "    nefi_output = [s for s in nefi_outputs if num_str in s]\n",
    "    #ensure there is only one location in this list\n",
    "    assert len(nefi_output)==1\n",
    "    #read in graph G\n",
    "    graph_in = nx.read_multiline_adjlist(nefi_output[0],delimiter='|')\n",
    "\n",
    "    #compute both radial inward and radial outward filtrations\n",
    "    for direction in ['inward','outward']:\n",
    "    \n",
    "        filename_header = write_folder+data_name+file_name+num_str+\"_\"+direction\n",
    "    \n",
    "        diag = radius_filtration(graph_in,max_rad=max_rad,filename_save = filename_header+\"_persistence\",direction=direction)\n",
    "    \n",
    "        b0,b1,r = betti_curve(diag,r0=0,r1=40,filename_save = filename_header+\"_Betti\")\n",
    "        \n",
    "        PI_o, PI_r = Persist_im(diag=diag, inf_val = 40,sigma = 1.0, filename_save = [filename_header+\"_PIO\",\n",
    "                                                                                      filename_header+\"_PIR\"])\n",
    "\n",
    "print(f\"Computing radial filtrations for {dataset}\")          \n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = pool.map(radial_filtrations, nums)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Flooding filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flood_filtration(num):\n",
    "\n",
    "    if dataset == \"all\":\n",
    "        num_str = num\n",
    "    else:\n",
    "        num_str = f\"{str(num).zfill(4)}\"\n",
    "    \n",
    "    #load in image\n",
    "    image_loc = f\"{image_folder}{file_name}{num_str}.png\"\n",
    "    image = mpimg.imread(image_loc)\n",
    "    \n",
    "    if dataset == \"HRF\":\n",
    "        #downsample to ease computation\n",
    "        image = skimage.measure.block_reduce(image,(3,3),np.max)\n",
    "    \n",
    "    filename_header = write_folder+data_name+file_name+num_str+\"_flooding\"\n",
    "    \n",
    "    try:\n",
    "        diag = level_set_flooding(image[:,:,0],iter_num=35,steps=2,filename = filename_header+\"_persistence\")\n",
    "    except:\n",
    "        diag = level_set_flooding(image,       iter_num=35,steps=2,filename = filename_header+\"_persistence\")\n",
    "\n",
    "    b0,b1,r = betti_curve(diag,r0=0,r1=35,filename_save = filename_header+\"_Betti\")\n",
    "    \n",
    "    PI_o, PI_r = Persist_im(diag=diag, sigma = 1.0, inf_val = 35,filename_save = [filename_header+\"_PIO\",filename_header+\"_PIR\"])\n",
    "\n",
    "print(f\"Computing flooding filtration for {dataset}\")      \n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = pool.map(flood_filtration, nums)\n",
    "pool.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VR filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define weighting for persistence images for ripser\n",
    "def weight_ramp(x):\n",
    "    \n",
    "    if np.any(np.isinf(x)):\n",
    "        weight = 1.0\n",
    "    else:\n",
    "        weight = x[1]/185\n",
    "    \n",
    "    return weight\n",
    "\n",
    "def VR_filtration(num):\n",
    "    \n",
    "    if \"all\" in dataset:\n",
    "        num_str = num\n",
    "    else:\n",
    "        num_str = f\"{str(num).zfill(4)}\"\n",
    "    \n",
    "    #load in image\n",
    "    image_loc = f\"{image_folder}{file_name}{num_str}.png\"\n",
    "    image = mpimg.imread(image_loc)\n",
    "    \n",
    "    if dataset == \"HRF\":\n",
    "        #downsample for HRF to ease computation\n",
    "        image = skimage.measure.block_reduce(image,(3,3),np.max)\n",
    "    \n",
    "    #saving\n",
    "    filename_header = write_folder+data_name+file_name+num_str+\"_VR\"\n",
    "    \n",
    "    #convert image to pointcloud\n",
    "    try:\n",
    "        pointcloud = image_to_pointcloud(image[:,:,0])\n",
    "    except:\n",
    "        pointcloud = image_to_pointcloud(image)    \n",
    "    pointcloud = np.array(pointcloud)\n",
    "\n",
    "    #initialize averaged PIs for each descriptor vector\n",
    "    im0_ripser_ramp = np.zeros((2500,))\n",
    "    im1_ripser_ramp = np.zeros((2500,))\n",
    "    im0_ripser_ones = np.zeros((2500,))\n",
    "    im1_ripser_ones = np.zeros((2500,))\n",
    "    \n",
    "    np.random.seed(10)\n",
    "    \n",
    "    #average over 50 subsamplings\n",
    "    for i in np.arange(50):\n",
    "    \n",
    "        #shuffle pointcloud\n",
    "        np.random.shuffle(pointcloud)\n",
    "    \n",
    "        #Run VR on subsampled pointcloud\n",
    "        dgms = ripser.ripser(pointcloud, n_perm = 2000)['dgms']\n",
    "        \n",
    "        #Save the persistence diagram\n",
    "        save_BD(dgms, filename = f\"{filename_header}_persistence_{i}\")\n",
    "\n",
    "        #Compute the Persistence images with ramped weighting\n",
    "        persistence_image = vector_methods.PersistenceImage(resolution = [50,50],\n",
    "                                                            im_range = [0,185,0,185],\n",
    "                                                            weight = weight_ramp)    \n",
    "        im0_ripser, im1_ripser = persistence_image.transform(dgms)\n",
    "        \n",
    "        im0_ripser_ramp += im0_ripser\n",
    "        im1_ripser_ramp += im1_ripser\n",
    "        \n",
    "        #with one weighting    \n",
    "        persistence_image = vector_methods.PersistenceImage(resolution = [50,50],\n",
    "                                                            im_range = [0,185,0,185])    \n",
    "        im0_ripser, im1_ripser = persistence_image.transform(dgms)\n",
    "        \n",
    "        im0_ripser_ones += im0_ripser\n",
    "        im1_ripser_ones += im1_ripser\n",
    "    \n",
    "    im0_ripser_ramp /= 50.0\n",
    "    im1_ripser_ramp /= 50.0\n",
    "    im0_ripser_ones /= 50.0\n",
    "    im1_ripser_ones /= 50.0\n",
    "    \n",
    "    #Save Persistence image results\n",
    "    data = {}\n",
    "    data['Ip'] = []\n",
    "    data['Ip'].append(im0_ripser_ramp)\n",
    "    data['Ip'].append(im1_ripser_ramp)\n",
    "    np.save(f\"{filename_header}_PIR\",data)\n",
    "    \n",
    "    data = {}\n",
    "    data['Ip'] = []\n",
    "    data['Ip'].append(im0_ripser_ones)\n",
    "    data['Ip'].append(im1_ripser_ones)\n",
    "    np.save(f\"{filename_header}_PIO\",data)\n",
    "\n",
    "    \n",
    "print(f\"Computing VR filtration for {dataset}\")    \n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = pool.map(VR_filtration, nums)\n",
    "pool.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
